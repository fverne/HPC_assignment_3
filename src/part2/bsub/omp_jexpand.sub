#!/bin/bash
# 02614 - High-Performance Computing, January 2024
# 
# batch script to run matmult on a dedicated GPU server in the hpcintrogpu
# queue
#
# Author: Bernd Dammann <bd@cc.dtu.dk>
#         Hans Henrik Brandenborg SÃ¸rensen <hhbs@dtu.dk>
#
#BSUB -J omp_jexpand
#BSUB -o output/omp_jexpand_%J.out
#BSUB -e output/omp_jexpand_%J.err
#BSUB -q hpcintrogpu
#BSUB -n 32
#BSUB -R "rusage[mem=2048]"
#BSUB -W 1:00
#BSUB -R "span[hosts=1]"
#BSUB -gpu "num=1:mode=exclusive_process"

# EXECUTABLE="poisson_jexpand"
# just pass executable poisson_jomp
# or pass poisson_expand (same script to compare both)
# echo -e "Executable name: ${EXECUTABLE}"
EXECUTABLE="poisson_jexpand"

# Tolerance is not actually used at these scripts, just there for the
# sake of the argument
N_SIZES="50 100 200 400 800 1000"
THREADS="1 2 4 8 10 16 20 30 36 40"
TOLERANCE="0.001"
ITER_MAX=500000
START_VALUE="0.0"
EXTRA_ARGS=4

# load module for shared cuda libraries
module load /appl9/nvhpc/2023_2311/modulefiles/nvhpc-nompi/23.11

cd ..
make clean && make -j 12  > /dev/null 2>&1

for N in $N_SIZES; do
    for THREAD in $THREADS; do
        export OMP_NUM_THREADS=${THREAD:-1}
    echo "OMP_NUM_THREADS=$OMP_NUM_THREADS"
    ./$EXECUTABLE $N $ITER_MAX $TOLERANCE $START_VALUE $EXTRA_ARGS
    done
done
